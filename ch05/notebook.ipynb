{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Real-World NLP Applications Using PyTorch 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 : Recurrent Neural Nets and Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, **Recurrent Neural Networks (RNNs)** can be u**sed for any task where data can be represented as a sequence**. We commonly use RNNs in NLP as text can be thought of as a sequence of individual words and can be modeled as such. While **a conventional neural network takes a single vector as input to the model**, an **RNN can take a whole sequence of vectors**. If we represent **each word in a document as a vector embedding**, we can represent a **whole document as a sequence of vectors** (or an order $3$ tensor). We can then use RNNs (and a more sophisticated form of RNN known as Long Short-Term Memory (LSTM) to learn from our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs consist of recurrent layers. While they are similar in many ways to the fully connected layers within a standard feed forward neural network, **these recurrent layers consist of a hidden state that is updated at each step of the sequential input**.\\\n",
    "This means that **for any given sequence, the model is initialized with a hidden state, often represented as a $1$-dimensional vector**.\\\n",
    "**The first step of our sequence is then fed into our model** and **the hidden state is updated depending on some learned parameters**.\\\n",
    "**The second word is then fed into the network and the hidden state is updated again depending on some other learned parameters**.\n",
    "\n",
    "These steps are repeated until the whole sequence has been processed and we are left with the final hidden state. **This computation loop, with the hidden state carried over from the previous computation and updated**, is why we refer to these **networks as recurrent**.\\\n",
    "This **final hidden state is then connected to a further fully connected layer** and a final classification is predicted.\n",
    "\n",
    "Our recurrent layer looks something like the following, where **$h$ is the hidden state** and **$x$ is our input at various time steps in our sequence**. For each iteration, **we update our hidden state at each time step**, $x$:\n",
    "\n",
    "![](recurrent_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expand this out to the whole sequence of time steps\n",
    "\n",
    "![](seq_time_steps.png)\n",
    "\n",
    "This layer is for **an input that is $n$ time steps long**. Our hidden state is initialized in state $h_0$, and then uses our first input, $x_1$, to compute the next hidden state, $h_1$. There are $2$ sets of weight matrices that are also learned—matrix $U$, which learns **how the hidden state changes between time steps**, and matrix $W$, which learns **how each input step affects the hidden state**.\n",
    "\n",
    "We also apply a $tanh$ activation function to the resulting product, **keeping the values of the hidden state between $-1$ and $1$**. The **equation for calculating any hidden state**, $h_t$, becomes the following:\n",
    "\n",
    "$h_t = tanh(Wh_{t-1} + Ux_t)$\n",
    "\n",
    "This is then repeated for each time step within our input sequence, and the final output for this layer is our last hidden state, $h_n$\n",
    "\n",
    "We will see later that **we can actually take the hidden state at each time step, rather than using the final hidden state, which is useful for sequence-to-sequence translation tasks in NLP**. However, for the time being, we will just take the hidden layer as output to the rest of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using RNNs for sentiment analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will become a classification task (where the two classes are negative/positive). Our sentence is **passed through a layer of learned word embeddings to form a representation of the sentence comprising several vectors (one for each word)**.\\\n",
    "These vectors are then **fed sequentially into our RNN layer and the final hidden state is passed through another fully connected layer**\\\n",
    "Our model's **output is a single value between $0$ and $1$**, depending on whether our model predicts a *negative* or *positive* sentiment from the sentence. This means our complete classification model looks like this:\n",
    "\n",
    "![](classification_model.png)\n",
    "\n",
    "Now, we will highlight one of the issues with ***RNNs—exploding and shrinking gradients***—and how we can remedy this using ***gradient clipping***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploding and shrinking gradients**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the recursive layer as a very deep network. When calculating the gradients, we do so at every iteration of the hidden state. **If the gradient of the loss relative to the weights at any given position becomes very big, this will have a multiplicative effect as it feeds forward** through all the iterations of the recurrent layer. This can cause **gradients to explode as they get very large very quickly**. If we have large gradients, this can **cause instability in our network**.\n",
    "\n",
    "On the other hand, if the **gradients within our hidden state are very small**, this will again have a **multiplicative effect and the gradients will be close to $0$**. This means that the **gradients can become too small to accurately update our parameters via gradient descent**, meaning our **model fails to learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gradient clipping** limits our gradients to prevent them from becoming too large. We simply choose a hyperparameter, $C$, and can **calculate our clipped gradient**, as follows:\n",
    "\n",
    "$||\\nabla L||_c = max(||\\nabla L||, C)$\n",
    "\n",
    "The following graph shows the relationship between the two variables\n",
    "\n",
    "![](comparaison_gradient_clipping.png)\n",
    "\n",
    "Another technique we can use to prevent exploding or disappearing gradients is **to shorten our input sequence length**. The **effective depth of our recurrent layer depends on the length of our input sequence as the sequence length determines how many iterative updates we need to perform on our hidden state**. The **fewer number of steps in this process, the smaller the multiplicative effects** of the gradient accumulation between hidden states will be. By intelligently picking the maximum sequence length as a hyperparameter in our model, we can help prevent exploding and vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducting LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs suffer from two main flaws, which can be partially remedied by using a more sophisticated version of the RNN, known as **LSTM**.\\\n",
    "The basic structure of RNNs means that **it is very difficult for them to retain information long term**\n",
    "\n",
    "> Consider a sentence that's 20 words long. From our first word in the sentence affecting the initial hidden state to the last word in the sentence, our hidden state is updated 20 times. From the beginning of our sentence to our final hidden state, it is very difficult for an RNN to retain information about words at the beginning of the sentence. This means that RNNs aren't very good at capturing long-term dependencies within sequences. This also ties in with the vanishing gradient problem mentioned earlier, where it is very inefficient to backpropagate through long, sparse sequences of vectors\n",
    "\n",
    "> Consider a long paragraph where we are trying to predict the next word. The sentence begins with `I study math…` and ends with `my final exam is in…`. Intuitively, we would expect the next word to be `math` or some math-related field. However, in an RNN model on a long sequence, our hidden state may struggle to retain the information for the beginning of the sentence by the time it reaches the end of the sentence as it takes multiple update steps.\n",
    "\n",
    "RNNs are poor at capturing the context of words within a sentence as a whole. Within an RNN, our hidden state updates in one direction only. In a single forward pass, our hidden state is initialized and the first word in the sequence is passed into it. This process is then repeated with all the subsequent words in the sentence sequentially until we are left with our final hidden state. This means that for any given word in a sentence, we have only considered the cumulative effect of the words that have occurred before it in the sentence up to that point. We do not consider any words that follow it, meaning we do not capture the full context of each word in the sentence.\n",
    "\n",
    "> In another example, we again want to predict the missing word in a sentence, but it now occurs toward the beginning as opposed to at the end. We have the sentence `I grew up in…so I can speak fluent Dutch`. Here, we can intuitively guess that the person grew up in the *Netherlands* from the fact that they speak Dutch. However, because an RNN parses this information sequentially, it would only use I grew up in… to make a prediction, missing the other key context within the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Working with LSTMs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more advanced versions of RNNs and contain two extra properties—an **update gate** and a **forget gate**. These two additions make it easier for the network to learn long-term dependencies. Consider the following film review\n",
    "\n",
    "*The film was amazing. I went to see it with my wife and my daughters on Tuesday afternoon. Although I didn't expect it to be very entertaining, it turned out to be loads of fun. We would definitely go back and see it again given the chance.*\n",
    "\n",
    "In sentiment analysis, it is clear that not all of the words in the sentence are relevant in determining whether it is a positive or negative review. We will repeat this sentence, but this time highlighting the words that are relevant to gauging the sentiment of the review:\n",
    "\n",
    "*The film was amazing. I went to see it with my wife and my daughters on Tuesday afternoon. Although I didn't expect it to be very entertaining, it turned out to be loads of fun. We would definitely go back and see it again given the chance.*\n",
    "\n",
    "**LSTMs attempt to do exactly this—remember the relevant words within a sentence while forgetting all the irrelevant information.** By doing this, **it stops the irrelevant information from diluting the relevant information, meaning long-term dependencies can be better learned across long sequences.**\n",
    "\n",
    "LSTMs are very similar in structure to RNNs. While there is a hidden state that is carried over between steps within the LSTM, the inner workings of the LSTM cell itself are different from that of the RNN\n",
    "\n",
    "![](lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LSTM cells**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While an RNN cell just takes the previous hidden state and the new input step and calculates the next hidden state using some learned parameters, the inner workings of an LSTM cell are significantly more complicated:\n",
    "\n",
    "![](inner_working_lstm_cell.png)\n",
    "\n",
    "We will first look at the **forget gate** (indicated by the bold rectangle):\n",
    "\n",
    "![](forget_gate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **forget gate essentially learns which elements of the sequence to forget**. The **previous hidden state**, $h_{t-1}$, and **the latest input step**, $x_1$, are **concatenated together and passed through a matrix of learned weights on the forget gate and a sigmoid function that squashes the values between $0$ and $1$**\\\n",
    "This resulting matrix, $f_t$, **is multiplied pointwise by the cell state from the previous step**, $c_{t-1}$. This effectively **applies a mask to the previous cell state so that only the relevant information from the previous cell state is brought forward**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at the **input gate**:\n",
    "\n",
    "![](input_gate.png)\n",
    "\n",
    "The input gate again takes the concatenated previous hidden state, ht-1, and the current sequence input, xt, and passes this through a sigmoid function with learned parameters, which outputs another matrix, it, consisting of values between 0 and 1. The concatenated hidden state and sequence input also pass through a tanh function, which squashes the output between -1 and 1. This is multiplied by the it matrix. This means that the learned parameters required to generate it effectively earn which elements should be kept from the current time step in our cell state. This is then added to the current cell state to get our final cell state, which will be carried over to the next time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the last element of the LSTM cell—the output gate:\n",
    "\n",
    "![](output_gate.png)\n",
    "\n",
    "The **output gate calculates the final output of the LSTM cell**—both the cell state and the hidden state that is carried over to the next step. The cell state, $c_t$, **is unchanged from the previous two steps** and is **a product of the forget gate and the input gate**. The **final hidden state**, $h_t$, is calculated by taking **the concatenated previous hidden state, $h_{t-1}$, and the current time step input, $x_t$**, and passing **through a sigmoid function with some learned parameters** to get **the output gate output**, $o_t$. The **final cell state**, $c_t$, is **passed through a $tanh$ function and multiplied by the output gate output**, $o_t$, to calculate the **final hidden state**, $h_t$. This means that **the learned parameters on the output gate effectively control which elements of the previous hidden state and current output are combined with the final cell state to carry over to the next time step as the new hidden state**.\n",
    "\n",
    "In our forward pass, we simply iterate through the model, initializing our hidden state and cell state and updating them at each time step using the LSTM cells until we are left with a final hidden state, which is output to the next layer of our neural network. By backpropagating through all the layers of our LSTM, we can calculate the gradients relative to the loss of the network and so we know which direction to update our parameters through gradient descent. We get several matrices or parameters—one for the input gate, one for the output gate, and one for the forget gate.\n",
    "\n",
    "Because we get more parameters than for a simple RNN and our computation graph is more complex, the process of backpropagating through the network and updating the weights will likely take longer than for a simple RNN. However, despite the longer training time, we have shown that LSTM offers significant advantages over a conventional RNN as the output gate, input gate, and forget gate all combine to give the model the ability to determine which elements of the input should be used to update the hidden state and which elements of the hidden state should be forgotten going forward, which means the model is better able to form long-term dependencies and retain information from previous sequence steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously mentioned that a downside of simple RNNs is that they fail to capture the full context of a word within a sentence as they are backward-looking only. At each time step of the RNN, only the previously seen words are considered and the words occurring next within the sentence are not taken into account. While basic LSTMs are similarly backward-facing, we can use a modified version of LSTM, known as a bidirectional LSTM, which considers both the words before and after it at each time step within the sequence.\n",
    "\n",
    "Bidirectional LSTMs process sequences in regular order and reverse order simultaneously, maintaining two hidden states. We'll call the forward hidden state ft and use rt for the reverse hidden state:\n",
    "\n",
    "![](bidirectional_lstm_process.png)\n",
    "\n",
    "Here, we can see that **we maintain these two hidden states throughout the whole proces**s and **use them to calculate a final hidden state**, $h_t$. Therefore, if we **wish to calculate the final hidden state** at time step $t$, we use the **forward hidden state, $f_t$,** which has seen all words up to and including input $x_t$, as well as the **reverse hidden state**, $r_t$, which **has seen all the words after and including $x_t$**. Therefore, our **final hidden state**, $h_t$, **comprises hidden states that have seen all the words in the sentence, not just the words occurring before time step** $t$. This means that **the context of any given word within the whole sentence can be better captured**. Bidirectional LSTMs have proven to offer improved performance on several NLP tasks over conventional unidirectional LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a sentiment analyzer using LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>These are the central themes of the film and t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>GO AND SEE IT!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>The sets (especially designed to work with the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>Nice Sound.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>Very very fun chef.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Sentiment\n",
       "140   These are the central themes of the film and t...         0\n",
       "677                                    GO AND SEE IT!           1\n",
       "383   The sets (especially designed to work with the...         1\n",
       "2666                                        Nice Sound.         1\n",
       "1232                                Very very fun chef.         1"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"./sentiment labelled sentences/sentiment.txt\") as f:\n",
    "    reviews = f.read()\n",
    "\n",
    "data = pd.DataFrame([review.split('\\t') for review in reviews.split('\\n')])\n",
    "data.columns = ['Review', 'Sentiment']\n",
    "data = data.sample(frac=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a function to tokenize our data, splitting each review into a list of individual preprocessed words. We loop through our dataset and for each review, we remove any punctuation, convert letters into lowercase, and remove any trailing whitespace. We then use the NLTK tokenizer to create individual tokens from this preprocessed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['these',\n",
       " 'are',\n",
       " 'the',\n",
       " 'central',\n",
       " 'themes',\n",
       " 'of',\n",
       " 'the',\n",
       " 'film',\n",
       " 'and',\n",
       " 'they',\n",
       " 'are',\n",
       " 'handled',\n",
       " 'ineptly',\n",
       " 'stereotypically',\n",
       " 'and',\n",
       " 'with',\n",
       " 'no',\n",
       " 'depth',\n",
       " 'of',\n",
       " 'imagination']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def split_words_reviews(data):\n",
    "    text = list(data['Review'].values)\n",
    "    clean_text = []\n",
    "    for t in text:\n",
    "        clean_text.append(t.translate(str.maketrans('', '', punctuation)).lower().rstrip())\n",
    "    tokenized = [word_tokenize(x) for x in clean_text]\n",
    "    all_text = []\n",
    "    for tokens in tokenized:\n",
    "        for t in tokens:\n",
    "            all_text.append(t)\n",
    "\n",
    "    return tokenized, set(all_text)\n",
    "\n",
    "reviews, vocab = split_words_reviews(data)\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return the reviews themselves, as well as a set of all words within all the reviews (that is, the vocabulary/corpus), which we will use to create our vocab dictionaries.\n",
    "\n",
    "In order to fully prepare our sentences for entry into a neural network, we must convert our words into numbers. In order to do this, we create a couple of dictionaries, which will allow us to convert data from word into index and from index into word. To do this, we simply loop through our corpus and assign an index to each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'but',\n",
       " 2: 'cell',\n",
       " 3: 'running',\n",
       " 4: 'tragedy',\n",
       " 5: 'id',\n",
       " 6: 'sinking',\n",
       " 7: 'hottest',\n",
       " 8: 'dropped',\n",
       " 9: 'effects',\n",
       " 10: 'tick',\n",
       " 11: 'inexpensive',\n",
       " 12: 'install',\n",
       " 13: 'nerves',\n",
       " 14: 'satisifed',\n",
       " 15: 'awkward',\n",
       " 16: 'defeats',\n",
       " 17: 'petrified',\n",
       " 18: 'miniseries',\n",
       " 19: 'boyfriend',\n",
       " 20: 'out',\n",
       " 21: 'vx',\n",
       " 22: 'trashy',\n",
       " 23: 'middleaged',\n",
       " 24: 'salesman',\n",
       " 25: 'toilet',\n",
       " 26: 'gyro',\n",
       " 27: 'lasting',\n",
       " 28: 'flynn',\n",
       " 29: 'gave',\n",
       " 30: 'dodge',\n",
       " 31: 'burtons',\n",
       " 32: 'airport',\n",
       " 33: 'exemplars',\n",
       " 34: 'down',\n",
       " 35: 'spend',\n",
       " 36: 'ignored',\n",
       " 37: 'pixel',\n",
       " 38: 'wouldbe',\n",
       " 39: 'cbr',\n",
       " 40: 'dog',\n",
       " 41: 'blow',\n",
       " 42: 'earset',\n",
       " 43: 'effect',\n",
       " 44: 'phantasm',\n",
       " 45: 'nano',\n",
       " 46: 'buyit',\n",
       " 47: 'fits',\n",
       " 48: 'camerawork',\n",
       " 49: 'andor',\n",
       " 50: 'view',\n",
       " 51: 'ad',\n",
       " 52: 'catching',\n",
       " 53: 'freedom',\n",
       " 54: 'japanese',\n",
       " 55: 'survivors',\n",
       " 56: 'scallop',\n",
       " 57: 'memory',\n",
       " 58: 'comedic',\n",
       " 59: 'cow',\n",
       " 60: 'about',\n",
       " 61: 'brilliance',\n",
       " 62: 'buldogis',\n",
       " 63: 'sour',\n",
       " 64: 'girolamo',\n",
       " 65: 'spots',\n",
       " 66: 'im',\n",
       " 67: 'curve',\n",
       " 68: 'unit',\n",
       " 69: 'hs850',\n",
       " 70: '40min',\n",
       " 71: 'difference',\n",
       " 72: 'interacting',\n",
       " 73: 'convincing',\n",
       " 74: 'cancelling',\n",
       " 75: 'paradise',\n",
       " 76: 'krussel',\n",
       " 77: 'values',\n",
       " 78: 'douchey',\n",
       " 79: 'overwrought',\n",
       " 80: 'jealousy',\n",
       " 81: 'unmoving',\n",
       " 82: 'moviegoing',\n",
       " 83: 'comical',\n",
       " 84: 'deserves',\n",
       " 85: 'bohemian',\n",
       " 86: 'selfdiscovery',\n",
       " 87: 'hostess',\n",
       " 88: 'peculiarity',\n",
       " 89: 'slurs',\n",
       " 90: 'middle',\n",
       " 91: 'misplace',\n",
       " 92: 'cocktail',\n",
       " 93: 'joy',\n",
       " 94: 'indeed',\n",
       " 95: 'always',\n",
       " 96: 'improvement',\n",
       " 97: 'buyer',\n",
       " 98: 'robert',\n",
       " 99: 'negulesco',\n",
       " 100: 'supposed',\n",
       " 101: 'universe',\n",
       " 102: 'upload',\n",
       " 103: 'nobu',\n",
       " 104: 'everything',\n",
       " 105: 'elk',\n",
       " 106: 'replenished',\n",
       " 107: 'internet',\n",
       " 108: 'anne',\n",
       " 109: 'hope',\n",
       " 110: 'bt50',\n",
       " 111: 'restart',\n",
       " 112: 'figured',\n",
       " 113: 'charcoal',\n",
       " 114: 'band',\n",
       " 115: 'adaptation',\n",
       " 116: 'stewart',\n",
       " 117: 'tech',\n",
       " 118: 'beforei',\n",
       " 119: 'falling',\n",
       " 120: 'bamboo',\n",
       " 121: 'garage',\n",
       " 122: 'overnite',\n",
       " 123: 'sites',\n",
       " 124: 'mouth',\n",
       " 125: 'know',\n",
       " 126: 'product',\n",
       " 127: 'whine',\n",
       " 128: 'characters',\n",
       " 129: 'ill',\n",
       " 130: 'people',\n",
       " 131: 'ages',\n",
       " 132: 'task',\n",
       " 133: 'straw',\n",
       " 134: 'iq',\n",
       " 135: 'potted',\n",
       " 136: 'hello',\n",
       " 137: 'tuneful',\n",
       " 138: 'hitchcock',\n",
       " 139: 'saggy',\n",
       " 140: 'fire',\n",
       " 141: 'qualities',\n",
       " 142: 'underlying',\n",
       " 143: 'appearance',\n",
       " 144: 'tries',\n",
       " 145: 'user',\n",
       " 146: 'doubt',\n",
       " 147: 'cranberrymmmm',\n",
       " 148: 'flip',\n",
       " 149: 'drain',\n",
       " 150: 'clearer',\n",
       " 151: 'school',\n",
       " 152: 'custer',\n",
       " 153: 'seamless',\n",
       " 154: 'howeverthe',\n",
       " 155: 'preparing',\n",
       " 156: 'ca42',\n",
       " 157: 'premise',\n",
       " 158: 'rip',\n",
       " 159: 'bean',\n",
       " 160: 'decor',\n",
       " 161: 'waste',\n",
       " 162: 'equipment',\n",
       " 163: '2007',\n",
       " 164: 'houses',\n",
       " 165: 'perfected',\n",
       " 166: 'excessive',\n",
       " 167: 'michael',\n",
       " 168: 'impression',\n",
       " 169: 'sisters',\n",
       " 170: 'last',\n",
       " 171: 'unbearably',\n",
       " 172: 'affleck',\n",
       " 173: 'super',\n",
       " 174: 'tensions',\n",
       " 175: '20th',\n",
       " 176: 'howell',\n",
       " 177: 'dads',\n",
       " 178: 'actingwise',\n",
       " 179: 'fabulous',\n",
       " 180: 'modern',\n",
       " 181: 'silly',\n",
       " 182: 'spoiled',\n",
       " 183: 'thorn',\n",
       " 184: 'transcendant',\n",
       " 185: 'shows',\n",
       " 186: 'soooo',\n",
       " 187: 'actions',\n",
       " 188: 'follows',\n",
       " 189: 'upas',\n",
       " 190: 'succeeded',\n",
       " 191: 'shape',\n",
       " 192: 'explorations',\n",
       " 193: 'mind',\n",
       " 194: 'hinge',\n",
       " 195: 'improvisation',\n",
       " 196: 'is',\n",
       " 197: 'intensity',\n",
       " 198: 'shouting',\n",
       " 199: 'words',\n",
       " 200: 'edward',\n",
       " 201: 'characterisation',\n",
       " 202: 'seen',\n",
       " 203: 'reasonably',\n",
       " 204: 'blue',\n",
       " 205: 'reliability',\n",
       " 206: 'thanks',\n",
       " 207: 'literally',\n",
       " 208: 'consider',\n",
       " 209: 'purã©ed',\n",
       " 210: 'scratched',\n",
       " 211: 'park',\n",
       " 212: 'arrival',\n",
       " 213: 'silent',\n",
       " 214: 'somehow',\n",
       " 215: 'europe',\n",
       " 216: 'cheap',\n",
       " 217: 'razor',\n",
       " 218: 'sugary',\n",
       " 219: 'tricky',\n",
       " 220: 'skimp',\n",
       " 221: 'shirt',\n",
       " 222: 'smile',\n",
       " 223: 'drunk',\n",
       " 224: 'simplifying',\n",
       " 225: 'communication',\n",
       " 226: 'redeeming',\n",
       " 227: 'drift',\n",
       " 228: 'adorablethe',\n",
       " 229: 'hbo',\n",
       " 230: 'smoother',\n",
       " 231: 'mesmerising',\n",
       " 232: 'bite',\n",
       " 233: 'tracfonewebsite',\n",
       " 234: 'fixes',\n",
       " 235: 'producer',\n",
       " 236: 'couldnt',\n",
       " 237: 'acted',\n",
       " 238: 'callings',\n",
       " 239: 'latin',\n",
       " 240: 'backlight',\n",
       " 241: 'typical',\n",
       " 242: 'runs',\n",
       " 243: 'win',\n",
       " 244: 'lap',\n",
       " 245: 'baaaaaad',\n",
       " 246: 'initially',\n",
       " 247: 'donut',\n",
       " 248: 'sobering',\n",
       " 249: 'energy',\n",
       " 250: 'laughable',\n",
       " 251: 'fishnet',\n",
       " 252: 'heard',\n",
       " 253: 'brigand',\n",
       " 254: 'tots',\n",
       " 255: 'loudest',\n",
       " 256: 'subtitles',\n",
       " 257: 'dispenser',\n",
       " 258: 'children',\n",
       " 259: 'venue',\n",
       " 260: 'hayao',\n",
       " 261: 'communications',\n",
       " 262: 'much',\n",
       " 263: 'celluloid',\n",
       " 264: 'laughing',\n",
       " 265: 'excrutiatingly',\n",
       " 266: 'description',\n",
       " 267: 'timely',\n",
       " 268: 'terminology',\n",
       " 269: 'viewers',\n",
       " 270: 'earlier',\n",
       " 271: 'weird',\n",
       " 272: 'exploit',\n",
       " 273: 'years',\n",
       " 274: 'heart',\n",
       " 275: 'nay',\n",
       " 276: 'asleep',\n",
       " 277: 'randomly',\n",
       " 278: 'smoke',\n",
       " 279: 'bougth',\n",
       " 280: 'wontons',\n",
       " 281: 'beef',\n",
       " 282: 'wobbly',\n",
       " 283: 'waitress',\n",
       " 284: 'velvet',\n",
       " 285: 'success',\n",
       " 286: 'receptionsound',\n",
       " 287: 'seemed',\n",
       " 288: 'applifies',\n",
       " 289: 'chinese',\n",
       " 290: 'place',\n",
       " 291: '1',\n",
       " 292: 'being',\n",
       " 293: 'baba',\n",
       " 294: 'honor',\n",
       " 295: 'flaws',\n",
       " 296: 'stop',\n",
       " 297: 'breakfastlunch',\n",
       " 298: 'we',\n",
       " 299: 'astronauts',\n",
       " 300: 'beensteppedinandtrackedeverywhere',\n",
       " 301: 'husband',\n",
       " 302: 'hero',\n",
       " 303: 'sangria',\n",
       " 304: 'crisp',\n",
       " 305: 'de',\n",
       " 306: 'handy',\n",
       " 307: 'fruit',\n",
       " 308: 'months',\n",
       " 309: 'tough',\n",
       " 310: 'considerable',\n",
       " 311: 'outta',\n",
       " 312: 'why',\n",
       " 313: 'smaller',\n",
       " 314: 'undoubtedly',\n",
       " 315: 'mishima',\n",
       " 316: 'indie',\n",
       " 317: 'core',\n",
       " 318: 'rich',\n",
       " 319: 'con',\n",
       " 320: 'so',\n",
       " 321: 'ranch',\n",
       " 322: 'cover',\n",
       " 323: 'delivering',\n",
       " 324: 'omelets',\n",
       " 325: 'murdered',\n",
       " 326: 'compliments',\n",
       " 327: 'believable',\n",
       " 328: 'wong',\n",
       " 329: 'besides',\n",
       " 330: 'rightthe',\n",
       " 331: 'wifes',\n",
       " 332: 'warn',\n",
       " 333: 'needs',\n",
       " 334: 'deal',\n",
       " 335: 'handles',\n",
       " 336: 'intentions',\n",
       " 337: 'floor',\n",
       " 338: 'juicehighy',\n",
       " 339: 'lukewarm',\n",
       " 340: 'kids',\n",
       " 341: 'rice',\n",
       " 342: 'surprisingly',\n",
       " 343: 'protection',\n",
       " 344: 'george',\n",
       " 345: 'nevertheless',\n",
       " 346: 'suffers',\n",
       " 347: 'pointillistic',\n",
       " 348: 'tomorrow',\n",
       " 349: 'origins',\n",
       " 350: 'tried',\n",
       " 351: 'content',\n",
       " 352: 'bend',\n",
       " 353: 'lewis',\n",
       " 354: 'lousy',\n",
       " 355: 'accused',\n",
       " 356: 'mclaglen',\n",
       " 357: 'pleased',\n",
       " 358: 'attractive',\n",
       " 359: 'oil',\n",
       " 360: '70s',\n",
       " 361: 'stick',\n",
       " 362: 'commuter',\n",
       " 363: 'number',\n",
       " 364: 'comments',\n",
       " 365: 'biographical',\n",
       " 366: 'witnessed',\n",
       " 367: 'dissapointed',\n",
       " 368: 'maintains',\n",
       " 369: 'relationship',\n",
       " 370: '700w',\n",
       " 371: 'goldencrispy',\n",
       " 372: 'range',\n",
       " 373: 'goesthe',\n",
       " 374: 'ferry',\n",
       " 375: 'physical',\n",
       " 376: 'confortable',\n",
       " 377: 'brick',\n",
       " 378: 'meanings',\n",
       " 379: 'actorsan',\n",
       " 380: 'childhood',\n",
       " 381: 'happens',\n",
       " 382: 'dee',\n",
       " 383: 'unpredictability',\n",
       " 384: 'north',\n",
       " 385: 'entertainment',\n",
       " 386: 'lion',\n",
       " 387: 'anguish',\n",
       " 388: 'indescribably',\n",
       " 389: 'blatant',\n",
       " 390: 'madison',\n",
       " 391: 'stand',\n",
       " 392: 'timewaster',\n",
       " 393: 'string',\n",
       " 394: 'balls',\n",
       " 395: 'itbuy',\n",
       " 396: 'purcashed',\n",
       " 397: 'pics',\n",
       " 398: 'cgi',\n",
       " 399: 'slideshow',\n",
       " 400: 'vinegrette',\n",
       " 401: 'dropping',\n",
       " 402: 'static',\n",
       " 403: 'absolutely',\n",
       " 404: 'complexity',\n",
       " 405: 'ole',\n",
       " 406: 'expect',\n",
       " 407: 'sounded',\n",
       " 408: 'underacting',\n",
       " 409: 'act',\n",
       " 410: 'ended',\n",
       " 411: 'coming',\n",
       " 412: 'armband',\n",
       " 413: 'fine',\n",
       " 414: 'chase',\n",
       " 415: 'avoiding',\n",
       " 416: 'sooner',\n",
       " 417: 'enchanting',\n",
       " 418: 'superb',\n",
       " 419: 'surprises',\n",
       " 420: 'casing',\n",
       " 421: 'zombiez',\n",
       " 422: 'dialogue',\n",
       " 423: 'cheekbones',\n",
       " 424: 'four',\n",
       " 425: 'unremarkable',\n",
       " 426: 'drive',\n",
       " 427: 'company',\n",
       " 428: 'give',\n",
       " 429: 'masterpiece',\n",
       " 430: 'has',\n",
       " 431: 'and',\n",
       " 432: 'fat',\n",
       " 433: 'no',\n",
       " 434: 'worker',\n",
       " 435: 'jennifer',\n",
       " 436: 'disapointing',\n",
       " 437: 'bluetooth',\n",
       " 438: 'isâ…was',\n",
       " 439: 'snow',\n",
       " 440: 'hat',\n",
       " 441: 'starring',\n",
       " 442: 'downtown',\n",
       " 443: 'message',\n",
       " 444: 'soft',\n",
       " 445: 'bertolucci',\n",
       " 446: 'bars',\n",
       " 447: 'smiling',\n",
       " 448: 'attempting',\n",
       " 449: 'concerns',\n",
       " 450: 'fourth',\n",
       " 451: 'finest',\n",
       " 452: 'saw',\n",
       " 453: 'staff',\n",
       " 454: 'packed',\n",
       " 455: 'promptly',\n",
       " 456: 'riingtones',\n",
       " 457: 'blandly',\n",
       " 458: 'handled',\n",
       " 459: 'forgettable',\n",
       " 460: 'scary',\n",
       " 461: 'allergy',\n",
       " 462: 'enhanced',\n",
       " 463: 'comparablypriced',\n",
       " 464: 'discarded',\n",
       " 465: 'pizza',\n",
       " 466: 'wasnt',\n",
       " 467: 'publicly',\n",
       " 468: 'peanuts',\n",
       " 469: 'rating',\n",
       " 470: 'flowed',\n",
       " 471: 'apparently',\n",
       " 472: 'equivalent',\n",
       " 473: 'comprehensible',\n",
       " 474: 'replacement',\n",
       " 475: 'comment',\n",
       " 476: 'microphone',\n",
       " 477: 'saved',\n",
       " 478: 'study',\n",
       " 479: 'haunt',\n",
       " 480: 'depth',\n",
       " 481: 'vivian',\n",
       " 482: 'card',\n",
       " 483: 'latifas',\n",
       " 484: 'firehouse',\n",
       " 485: 'pros',\n",
       " 486: 'my',\n",
       " 487: 'unprofessional',\n",
       " 488: 'blown',\n",
       " 489: 'finished',\n",
       " 490: 'rick',\n",
       " 491: 'bone',\n",
       " 492: 'receives',\n",
       " 493: 'captures',\n",
       " 494: 'jeff',\n",
       " 495: 'hill',\n",
       " 496: 'service',\n",
       " 497: 'meats',\n",
       " 498: 'schultz',\n",
       " 499: 'disappointment',\n",
       " 500: 'entirely',\n",
       " 501: 'recognizes',\n",
       " 502: 'francisco',\n",
       " 503: 'sharing',\n",
       " 504: 'clichã©s',\n",
       " 505: 'trilogy',\n",
       " 506: 'kabuki',\n",
       " 507: 'acting',\n",
       " 508: 'disappoint',\n",
       " 509: 'closeups',\n",
       " 510: 'hold',\n",
       " 511: 'accomodate',\n",
       " 512: 'fall',\n",
       " 513: 'filmiing',\n",
       " 514: '8',\n",
       " 515: 'agreed',\n",
       " 516: 'downs',\n",
       " 517: 'taste',\n",
       " 518: 'exaggerating',\n",
       " 519: '6',\n",
       " 520: 'settings',\n",
       " 521: 'could',\n",
       " 522: 'days',\n",
       " 523: 'baseball',\n",
       " 524: 'its',\n",
       " 525: 'cinematic',\n",
       " 526: 'fondue',\n",
       " 527: 'wedges',\n",
       " 528: 'paper',\n",
       " 529: 'showthese',\n",
       " 530: 'anita',\n",
       " 531: 'maintaining',\n",
       " 532: 'dialing',\n",
       " 533: 'designer',\n",
       " 534: '3o',\n",
       " 535: 'national',\n",
       " 536: 'wanted',\n",
       " 537: 'holder',\n",
       " 538: 'additional',\n",
       " 539: 'favor',\n",
       " 540: 'yet',\n",
       " 541: 'history',\n",
       " 542: 'bits',\n",
       " 543: 'sergeant',\n",
       " 544: 'uploaded',\n",
       " 545: 'heres',\n",
       " 546: 'listed',\n",
       " 547: 'juano',\n",
       " 548: 'treated',\n",
       " 549: 'played',\n",
       " 550: 'parts',\n",
       " 551: 'moods',\n",
       " 552: 'wire',\n",
       " 553: 'ramseys',\n",
       " 554: 'gels',\n",
       " 555: 'jerky',\n",
       " 556: 'yaall',\n",
       " 557: 'awards',\n",
       " 558: 'phone',\n",
       " 559: 'appointments',\n",
       " 560: 'allot',\n",
       " 561: 'primal',\n",
       " 562: 'twist',\n",
       " 563: 'crema',\n",
       " 564: 'this',\n",
       " 565: 'decidely',\n",
       " 566: 'connoisseur',\n",
       " 567: '50',\n",
       " 568: 'organizational',\n",
       " 569: 'lino',\n",
       " 570: 'listener',\n",
       " 571: 'after',\n",
       " 572: 'fifteen',\n",
       " 573: 'distract',\n",
       " 574: 'charismafree',\n",
       " 575: 'hear',\n",
       " 576: 'nobody',\n",
       " 577: 'butter',\n",
       " 578: 'lame',\n",
       " 579: 'relations',\n",
       " 580: 'luck',\n",
       " 581: 'outgoing',\n",
       " 582: 'liking',\n",
       " 583: 'e715',\n",
       " 584: 'flirting',\n",
       " 585: 'pepperand',\n",
       " 586: '10',\n",
       " 587: 'yama',\n",
       " 588: 'buffets',\n",
       " 589: 'air',\n",
       " 590: 'pockets',\n",
       " 591: 'crispy',\n",
       " 592: 'meet',\n",
       " 593: 'amazingstylized',\n",
       " 594: 'gas',\n",
       " 595: 'onscreen',\n",
       " 596: 'among',\n",
       " 597: 'vessel',\n",
       " 598: 'sarcophage',\n",
       " 599: 'imperial',\n",
       " 600: 'hit',\n",
       " 601: 'incorrectness',\n",
       " 602: 'technology',\n",
       " 603: 'cutest',\n",
       " 604: 'dude',\n",
       " 605: 'ice',\n",
       " 606: 'reviews',\n",
       " 607: 'charges',\n",
       " 608: 'manufacturer',\n",
       " 609: 'evidently',\n",
       " 610: 'cat',\n",
       " 611: 'repertory',\n",
       " 612: 'serious',\n",
       " 613: 'sentiment',\n",
       " 614: 'insults',\n",
       " 615: 'missed',\n",
       " 616: 'underrated',\n",
       " 617: 'thus',\n",
       " 618: 'sit',\n",
       " 619: 'cailles',\n",
       " 620: 'lawyers',\n",
       " 621: 'defect',\n",
       " 622: 'geeky',\n",
       " 623: 'supposedly',\n",
       " 624: 'painted',\n",
       " 625: 'hayworth',\n",
       " 626: 'infatuated',\n",
       " 627: 'trying',\n",
       " 628: 'pecan',\n",
       " 629: 'laugh',\n",
       " 630: 'wonder',\n",
       " 631: 'insanely',\n",
       " 632: 'bluegreenscreen',\n",
       " 633: 'disposable',\n",
       " 634: 'portions',\n",
       " 635: 'bmw',\n",
       " 636: 'gay',\n",
       " 637: 'eew',\n",
       " 638: 'toactivate',\n",
       " 639: 'tailored',\n",
       " 640: 'women',\n",
       " 641: 'actors',\n",
       " 642: 'cakeohhh',\n",
       " 643: 'hoffmans',\n",
       " 644: 'stated',\n",
       " 645: 'players',\n",
       " 646: 'learn',\n",
       " 647: 'shoe',\n",
       " 648: 'decide',\n",
       " 649: 'receipt',\n",
       " 650: 'boasts',\n",
       " 651: 'fulci',\n",
       " 652: 'terror',\n",
       " 653: 'iffy',\n",
       " 654: 'spotty',\n",
       " 655: 'dominated',\n",
       " 656: 'easy',\n",
       " 657: 'plane',\n",
       " 658: 'house',\n",
       " 659: 'production',\n",
       " 660: 'rejection',\n",
       " 661: 'ground',\n",
       " 662: 'downloading',\n",
       " 663: 'themes',\n",
       " 664: 'earbugs',\n",
       " 665: 'unhappy',\n",
       " 666: 'baileys',\n",
       " 667: 'mess',\n",
       " 668: 'decipher',\n",
       " 669: 'muffled',\n",
       " 670: 'fair',\n",
       " 671: 'relaxing',\n",
       " 672: 'ups',\n",
       " 673: 'cooking',\n",
       " 674: 'pledge',\n",
       " 675: 'gorman',\n",
       " 676: 'chow',\n",
       " 677: 'english',\n",
       " 678: 'clicks',\n",
       " 679: 'rocketed',\n",
       " 680: 'proven',\n",
       " 681: 'sub',\n",
       " 682: 'reactions',\n",
       " 683: 'portrayed',\n",
       " 684: 'replace',\n",
       " 685: 'mad',\n",
       " 686: 'joins',\n",
       " 687: 'apple',\n",
       " 688: 'asia',\n",
       " 689: 'helpful',\n",
       " 690: 'signal',\n",
       " 691: 'keep',\n",
       " 692: 'still',\n",
       " 693: 'taelons',\n",
       " 694: 'tightly',\n",
       " 695: 'plants',\n",
       " 696: '17',\n",
       " 697: 'bbq',\n",
       " 698: 'suck',\n",
       " 699: 'correct',\n",
       " 700: 'recognition',\n",
       " 701: 'boy',\n",
       " 702: 'proceedings',\n",
       " 703: 'together',\n",
       " 704: 'return',\n",
       " 705: 'figure',\n",
       " 706: 'hybrid',\n",
       " 707: 'remorse',\n",
       " 708: 'lovable',\n",
       " 709: 'quick',\n",
       " 710: 'cutie',\n",
       " 711: 'smallest',\n",
       " 712: 'random',\n",
       " 713: 'neither',\n",
       " 714: 'little',\n",
       " 715: 'instruments',\n",
       " 716: 'it',\n",
       " 717: 'elses',\n",
       " 718: 'commands',\n",
       " 719: 'simple',\n",
       " 720: 'while',\n",
       " 721: 'slowmotion',\n",
       " 722: 'short',\n",
       " 723: 'partaking',\n",
       " 724: 'tell',\n",
       " 725: 'lane',\n",
       " 726: 'forward',\n",
       " 727: 'oh',\n",
       " 728: 'puzzlesolving',\n",
       " 729: 'noteworthy',\n",
       " 730: 'barney',\n",
       " 731: 'official',\n",
       " 732: 'sven',\n",
       " 733: 'feisty',\n",
       " 734: 'packaged',\n",
       " 735: 'gripping',\n",
       " 736: 'tasty',\n",
       " 737: 'reversestereotypes',\n",
       " 738: 'internetto',\n",
       " 739: 'affected',\n",
       " 740: 'battery',\n",
       " 741: 'existing',\n",
       " 742: 'predict',\n",
       " 743: 'plans',\n",
       " 744: 'right',\n",
       " 745: 'smoothly',\n",
       " 746: 'artistic',\n",
       " 747: '1995',\n",
       " 748: 'sensibility',\n",
       " 749: 'reaching',\n",
       " 750: 'using',\n",
       " 751: 'instant',\n",
       " 752: 'transfers',\n",
       " 753: 'louder',\n",
       " 754: 'killings',\n",
       " 755: 'beauty',\n",
       " 756: 'semi',\n",
       " 757: 'â–',\n",
       " 758: 'homework',\n",
       " 759: 'button',\n",
       " 760: 'mp3',\n",
       " 761: 'real',\n",
       " 762: 'composition',\n",
       " 763: 'fliptop',\n",
       " 764: 'trash',\n",
       " 765: 'delish',\n",
       " 766: 'pears',\n",
       " 767: 'meat',\n",
       " 768: 'interim',\n",
       " 769: 'impossible',\n",
       " 770: 'discovering',\n",
       " 771: 'drifting',\n",
       " 772: 'incredible',\n",
       " 773: 'creativity',\n",
       " 774: 'time',\n",
       " 775: 'soundtrack',\n",
       " 776: 'supporting',\n",
       " 777: 'seem',\n",
       " 778: 'en',\n",
       " 779: 'downside',\n",
       " 780: 'usual',\n",
       " 781: 'professor',\n",
       " 782: 'salad',\n",
       " 783: 'none',\n",
       " 784: 'taylor',\n",
       " 785: 'latch',\n",
       " 786: 'what',\n",
       " 787: 'focus',\n",
       " 788: 'pyromaniac',\n",
       " 789: 'final',\n",
       " 790: 'gadgets',\n",
       " 791: 'numerous',\n",
       " 792: 'w810i',\n",
       " 793: 'ray',\n",
       " 794: 'cartoon',\n",
       " 795: 'simply',\n",
       " 796: 'slackers',\n",
       " 797: 'buildings',\n",
       " 798: 'salads',\n",
       " 799: 'simmering',\n",
       " 800: 'sony',\n",
       " 801: 'eiko',\n",
       " 802: 'fireball',\n",
       " 803: 'includes',\n",
       " 804: 'punched',\n",
       " 805: 'pitch',\n",
       " 806: 'poop',\n",
       " 807: 'pine',\n",
       " 808: 'foxs',\n",
       " 809: 'division',\n",
       " 810: 'native',\n",
       " 811: 'unusable',\n",
       " 812: 'tables',\n",
       " 813: 'ethic',\n",
       " 814: 'are',\n",
       " 815: 'lance',\n",
       " 816: 'vocal',\n",
       " 817: 'pizzas',\n",
       " 818: 'brought',\n",
       " 819: 'hey',\n",
       " 820: 'busy',\n",
       " 821: 'thats',\n",
       " 822: 'bit',\n",
       " 823: 'finish',\n",
       " 824: 'containing',\n",
       " 825: 'unacceptible',\n",
       " 826: 'grandmother',\n",
       " 827: 'crowdpleaserthis',\n",
       " 828: 'cassette',\n",
       " 829: 'bucks',\n",
       " 830: 'enjoyment',\n",
       " 831: 'of',\n",
       " 832: 'becomes',\n",
       " 833: 'sanyo',\n",
       " 834: 'factor',\n",
       " 835: 'strength',\n",
       " 836: 'thick',\n",
       " 837: 'monica',\n",
       " 838: 'worth',\n",
       " 839: 'personally',\n",
       " 840: 'apology',\n",
       " 841: 'great',\n",
       " 842: 'vibe',\n",
       " 843: 'nigiri',\n",
       " 844: 'certain',\n",
       " 845: 'answer',\n",
       " 846: 'producers',\n",
       " 847: 'goth',\n",
       " 848: 'recommend',\n",
       " 849: 'borderlines',\n",
       " 850: 'matter',\n",
       " 851: 'strip',\n",
       " 852: 'mood',\n",
       " 853: 'loosely',\n",
       " 854: 'humour',\n",
       " 855: 'just',\n",
       " 856: 'smells',\n",
       " 857: 'tolerance',\n",
       " 858: 'interest',\n",
       " 859: 'edinburgh',\n",
       " 860: 'recommending',\n",
       " 861: 'par',\n",
       " 862: 'events',\n",
       " 863: 'eyes',\n",
       " 864: 'put',\n",
       " 865: 'main',\n",
       " 866: 'sprouts',\n",
       " 867: 'cool',\n",
       " 868: 'oven',\n",
       " 869: 'hugo',\n",
       " 870: 'photograph',\n",
       " 871: 'communicate',\n",
       " 872: 'styles',\n",
       " 873: 'delicioso',\n",
       " 874: 'occasional',\n",
       " 875: 'childlike',\n",
       " 876: 'plugged',\n",
       " 877: 'inhouse',\n",
       " 878: 'terribly',\n",
       " 879: 'loudly',\n",
       " 880: 'witticisms',\n",
       " 881: 'loves',\n",
       " 882: 'downright',\n",
       " 883: 'oriented',\n",
       " 884: 'bold',\n",
       " 885: 'solidify',\n",
       " 886: 'danceall',\n",
       " 887: 'unhealthy',\n",
       " 888: 'fries',\n",
       " 889: 'frequently4',\n",
       " 890: 'ringing',\n",
       " 891: 'prettier',\n",
       " 892: 'losing',\n",
       " 893: 'vanilla',\n",
       " 894: 'mickeys',\n",
       " 895: 'coppola',\n",
       " 896: 'cafe',\n",
       " 897: 'coppolas',\n",
       " 898: 'beers',\n",
       " 899: 'tear',\n",
       " 900: 'genius',\n",
       " 901: 'sundays',\n",
       " 902: 'dr',\n",
       " 903: 'bluetoothmotorola',\n",
       " 904: 'wrong',\n",
       " 905: 'beat',\n",
       " 906: 'miniusb',\n",
       " 907: 'cox',\n",
       " 908: 'delight',\n",
       " 909: 'unrestrained',\n",
       " 910: 'equally',\n",
       " 911: 'landline',\n",
       " 912: 'relatively',\n",
       " 913: 'generous',\n",
       " 914: 'one',\n",
       " 915: 'shrimp',\n",
       " 916: 'manages',\n",
       " 917: 'batteries',\n",
       " 918: 'pasta',\n",
       " 919: 'conflict',\n",
       " 920: 'unfortunate',\n",
       " 921: 'deliver',\n",
       " 922: 'arepas',\n",
       " 923: 'fresh',\n",
       " 924: 'jobs',\n",
       " 925: 'produced',\n",
       " 926: 'scripts',\n",
       " 927: 'drivng',\n",
       " 928: 'rpg',\n",
       " 929: 'flag',\n",
       " 930: 'way',\n",
       " 931: 'imagined',\n",
       " 932: 'potatoes',\n",
       " 933: 'instance',\n",
       " 934: 'medium',\n",
       " 935: 'twirling',\n",
       " 936: 'itfriendly',\n",
       " 937: 'wow',\n",
       " 938: 'clips',\n",
       " 939: 'sorely',\n",
       " 940: 'favorite',\n",
       " 941: 'errol',\n",
       " 942: 'occupied',\n",
       " 943: 'acceptable',\n",
       " 944: 'machine',\n",
       " 945: 'balance',\n",
       " 946: 'possesed',\n",
       " 947: 'rests',\n",
       " 948: 'indoor',\n",
       " 949: 'aversion',\n",
       " 950: 'worse',\n",
       " 951: 'outhe',\n",
       " 952: 'reset',\n",
       " 953: 'sandwiches',\n",
       " 954: 'upper',\n",
       " 955: 'local',\n",
       " 956: 'luvs',\n",
       " 957: 'freeway',\n",
       " 958: 'tickets',\n",
       " 959: 'tone',\n",
       " 960: 'change',\n",
       " 961: 'mystifying',\n",
       " 962: 'wires',\n",
       " 963: 'fisted',\n",
       " 964: 'contacts',\n",
       " 965: 'loud',\n",
       " 966: 'if',\n",
       " 967: 'front',\n",
       " 968: 'complaint',\n",
       " 969: 'stunning',\n",
       " 970: 'fifties',\n",
       " 971: 'trainroller',\n",
       " 972: 'eggs',\n",
       " 973: 'spoilers',\n",
       " 974: 'carlys',\n",
       " 975: 'underappreciated',\n",
       " 976: 'march',\n",
       " 977: 'menacing',\n",
       " 978: 'keypads',\n",
       " 979: 'moto',\n",
       " 980: 'configuration',\n",
       " 981: 'shatner',\n",
       " 982: 'thoughtprovoking',\n",
       " 983: 'jamaican',\n",
       " 984: 'eclectic',\n",
       " 985: 'vomited',\n",
       " 986: 'can',\n",
       " 987: 'candle',\n",
       " 988: 'jim',\n",
       " 989: 'treasure',\n",
       " 990: 'exclaim',\n",
       " 991: 'space',\n",
       " 992: 'warnings',\n",
       " 993: 'art',\n",
       " 994: 'thread',\n",
       " 995: 'naughty',\n",
       " 996: 'satisfied',\n",
       " 997: 'startac',\n",
       " 998: 'selfsacrifice',\n",
       " 999: 'lifetime',\n",
       " 1000: 'messages',\n",
       " ...}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dictionaries(words):\n",
    "    word_to_int_dict = {w:i+1 for i, w in enumerate(words)}\n",
    "    int_to_word_dict = {i:w for w, i in word_to_int_dict.items()}\n",
    "    return word_to_int_dict, int_to_word_dict\n",
    "\n",
    "word_to_int_dict, int_to_word_dict = create_dictionaries(vocab)\n",
    "int_to_word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network will take input of a fixed length; however, if we explore our reviews, we will see that our reviews are all of different lengths. In order to **ensure that all of our inputs are of the same length, we will pad our input sentences**. This essentially means that **we add empty tokens to shorter sentences so that all the sentences are of the same length**. We must first decide on the length of the padding we wish to implement. We first calculate the maximum length of a sentence in our input reviews, as well as the average length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "11.783333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.max([len(x) for x in reviews]))\n",
    "print(np.mean([len(x) for x in reviews]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the longest sentence is $70$ words long and the average sentence length has a length of $11.78$. To capture all the information from all our sentences, we want to pad all of our sentences so that they have a length of $70$. However, using longer sentences means longer sequences, which causes our LSTM layer to become deeper. This means model training takes longer as we have to backpropagate our gradients through more layers, but it also means that a large percentage of our inputs would just be sparse and full of empty tokens, which makes learning from our data much less efficient. This is illustrated by the fact that our maximum sentence length is much larger than our average sentence length. In order to capture the majority of our sentence information without unnecessarily padding our inputs and making them too sparse, we opt to use an input size of $50$. You may wish to experiment with using different input sizes between $20$ and $70$ to see how this affects your model performance.\n",
    "\n",
    "We will create a function that allows us to pad our sentences so that they are all the same size. For reviews shorter than the sequence length, we pad them with empty tokens. For reviews longer than the sequence length, we simply drop any tokens over the maximum sequence length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '', 'these', 'are',\n",
       "       'the', 'central', 'themes', 'of', 'the', 'film', 'and', 'they',\n",
       "       'are', 'handled', 'ineptly', 'stereotypically', 'and', 'with',\n",
       "       'no', 'depth', 'of', 'imagination'], dtype='<U33')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_text(tokenized_reviews, seq_length):\n",
    "    reviews = []\n",
    "    for review in tokenized_reviews:\n",
    "        if len(review) >= seq_length:\n",
    "            reviews.append(review[:seq_length])\n",
    "        else:\n",
    "            reviews.append(['']*(seq_length-len(review)) + review)\n",
    "    return np.array(reviews)\n",
    "padded_sentences = pad_text(reviews, seq_length=50)\n",
    "padded_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must make one further adjustment to allow the use of empty tokens within our model. Currently, our vocabulary dictionaries do not know how to convert empty tokens into integers to use within our network. Because of this, we manually add these to our dictionaries with index 0, which means empty tokens will be given a value of 0 when fed into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_word_dict[0] = ''\n",
    "word_to_int_dict[''] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now very nearly ready to begin training our model. We perform one final step of preprocessing and encode all of our padded sentences as numeric sequences for feeding into our neural network. This means that the previous padded sentence now looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0, 2443,  814, 1170,\n",
       "       2546,  663,  831, 1170, 3610,  431, 3051,  814,  458, 3167, 3850,\n",
       "        431, 3025,  433,  480,  831, 3674])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences = np.array([[word_to_int_dict[word] for word in review] for review in padded_sentences])\n",
    "encoded_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our input sequences encoded as numerical vectors, we are ready to begin designing our model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will consist of several main parts. Besides the input and output layers that are common to many neural networks, we will first require an **embedding layer**. This is so that our model learns the vector representations of the words it is being trained on. We could opt to use precomputed embeddings (such as GLoVe), but for demonstrative purposes, we will train our own embedding layer. Our input sequences are fed through the input layer and come out as sequences of vectors.\n",
    "\n",
    "These vector sequences are then fed into our **LSTM layer**. As explained in detail earlier in this chapter, the LSTM layer learns sequentially from our sequence of embeddings and outputs a single vector output representing the final hidden state of the LSTM layer. This final hidden state is finally passed through a further hidden layer before the final output node predicts a value between 0 and 1, indicating whether the input sequence was a positive or negative review. This means that our model architecture looks something like this:\n",
    "\n",
    "![](model_architecture.png)\n",
    "\n",
    "We will now demonstrate how to code this model from scratch using PyTorch. We create a class called `SentimentLSTM`, which inherits from the `nn.Module` class. We define our `init` parameters as the size of our vocab, the number of LSTM layers our model will have, and the size of our model's hidden state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, n_vocab, n_embed, n_hidden, n_output, n_layers, drop_p=.8):\n",
    "        super().__init__()\n",
    "        self.n_vocab = n_vocab\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first=True, dropout=drop_p)\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "        self.fc = nn.Linear(n_hidden, n_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_words):\n",
    "        embedded_words = self.embedding(input_words)\n",
    "        lstm_out, h = self.lstm(embedded_words)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        sigmoid_out = self.sigmoid(fc_out)\n",
    "        sigmoid_out = sigmoid_out.view(batch_size, -1)\n",
    "        sigmoid_last = sigmoid_out[:, -1]\n",
    "        return sigmoid_last, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        device = 'cuda'\n",
    "        weights = next(self.parameters()).data\n",
    "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\\\n",
    "            weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define each of the layers of our network. Firstly, we define our embedding layer, which will have the length of the number of words in our vocabulary and the size of the embedding vectors as a `n_embed` hyperparameter to be specified. Our LSTM layer is defined using the output vector size from the embedding layer, the length of the model's hidden state, and the number of layers that our LSTM layer will have. We also add an argument to specify that our LSTM can be trained on batches of data and an argument to allow us to implement network regularization via dropout. We define a further dropout layer with probability, drop_p (a hyperparameter to be specified on model creation), as well as our definitions of our final fully connected layer and output/prediction node (with a sigmoid activation function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define our forward pass within our model class. Within this forward pass, we just chain together the output of one layer to become the input into our next layer. Here, we can see that our embedding layer takes input_words as input and outputs the embedded words. Then, our LSTM layer takes embedded words as input and outputs lstm_out. The only nuance here is that we use `view()` to reshape our tensors from the LSTM output to be the correct size for input into our fully connected layer. The same also applies for reshaping the output of our hidden layer to match that of our output node. Note that our output will return a prediction for `class = 0` and `class = 1`, so we slice the output to only return a prediction for class = 1—that is, the probability that our sentence is positive:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "    def forward(self, input_words):\n",
    "        embedded_words = self.embedding(input_words)\n",
    "        lstm_out, h = self.lstm(embedded_words)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.n_hidden)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        sigmoid_out = self.sigmoid(fc_out)\n",
    "        sigmoid_out = sigmoid_out.view(batch_size, -1)\n",
    "        sigmoid_last = sigmoid_out[:, -1]\n",
    "        return sigmoid_last, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        device = 'cuda'\n",
    "        weights = next(self.parameters()).data\n",
    "        h = (weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device),\\\n",
    "            weights.new(self.n_layers, batch_size, self.n_hidden).zero_().to(device))\n",
    "        return h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then initialize our model by creating a new instance of the `SentimentLSTM` class. We pass the size of our vocab, the size of our embeddings, the size of our hidden state, as well as the output size, and the number of layers in our LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(word_to_int_dict)\n",
    "n_embed = 50\n",
    "n_hidden = 100\n",
    "n_output = 1\n",
    "n_layers = 2\n",
    "net = SentimentLSTM(n_vocab, n_embed, n_hidden, n_output, n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model, we must first define our datasets. We will train our model using a training set of data, evaluate our trained model at each step on a validation set, and then finally, measure our model's final performance using an unseen test set of data. The reason we use a test set that is separate from our validation training is that we may wish to fine-tune our model hyperparameters based on the loss against the validation set. If we do this, we may end up picking the hyperparameters that are only optimal in performance for that particular validation set of data. We evaluate a final time against an unseen test set to make sure our model generalizes well to data it hasn't seen before at any part of the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already defined our model inputs $(x)$ as encoded_sentences, but we must also define our model output $(y)$. We do this simply, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([int(x) for x in data['Sentiment'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our training and validation ratios. In this case, we will train our model on $80\\%$ of the data, validate on a further $10\\%$ of the data, and finally, test on the remaining $10\\%$ of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "valid_ratio = (1 - train_ratio)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use these ratios to slice our data and transform them into tensors and then tensor datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "total = len(encoded_sentences)\n",
    "train_cutoff = int(total * train_ratio)\n",
    "valid_cutoff = int(total * (1 - valid_ratio))\n",
    "train_x, train_y = torch.Tensor(encoded_sentences[:train_cutoff]).long(), torch.Tensor(labels[:train_cutoff]).long()\n",
    "valid_x, valid_y = torch.Tensor(encoded_sentences[train_cutoff:valid_cutoff]).long(), torch.Tensor(labels[train_cutoff:valid_cutoff]).long()\n",
    "test_x, test_y = torch.Tensor(encoded_sentences[valid_cutoff:]).long(), torch.Tensor(labels[valid_cutoff:]).long()\n",
    "train_data = TensorDataset(train_x, train_y)\n",
    "valid_data = TensorDataset(valid_x, valid_y)\n",
    "test_data = TensorDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use these datasets to create PyTorch `DataLoader` objects. DataLoader allows us to batch process our datasets with the `batch_size` parameter, allowing different batch sizes to be easily passed to our model. In this instance, we will keep it simple and set `batch_size = 1`, which means our model will be trained on individual sentences, rather than using larger batches of data. We also opt to randomly shuffle our DataLoader objects so that data is passed through our neural network in random order, rather than the same order each epoch, potentially removing any biased results from the training order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our `DataLoader` object for each of our three datasets, we define our training loop. We first define a number of hyperparameters, which will be used within our training loop. Most importantly, we define our loss function as `binary cross entropy` (as we are dealing with **predicting a single binary class**) and we define our optimizer to be `Adam` with a **learning rate** of $0.001$. We also define our model to run for a short number of epochs (to save time) and set clip = $5$ to define our gradient clipping:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import torch.optim as optim\n",
    "\n",
    "print_every = 2400\n",
    "step = 0\n",
    "n_epochs = 3\n",
    "clip = 5\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "# The main body of our training loop looks like this:\n",
    "for epoch in range(n_epochs):\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        step+=1\n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs)\n",
    "        loss = criterion(output, labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we just train our model for a number of epochs, and for every epoch, we first initialize our hidden layer using the batch size parameter. In this instance, we set `batch_size = 1` as we are just training our model one sentence at a time. For each batch of input sentences and labels within our train loader, we first zero our gradients (to stop them accumulating) and calculate our model outputs using the forward pass of our data using the model's current state. Using this output, we then calculate our loss using the predicted output from the model and the correct labels. We then perform a backward pass of this loss through our network to calculate the gradients at each stage. Next, we use the `grad_clip_norm()` function to clip our gradients as this will stop our gradients from exploding, as mentioned earlier in this chapter. We defined `clip = 5`, meaning the maximum gradient at any given node is 5. Finally, we update our weights using the gradients calculated on our backward pass by calling `optimizer.step()`.\n",
    "\n",
    "If we run this loop by itself, we will train our model. However, we want to evaluate our model performance after every epoch in order to determine its performance on a validation set of data. We do this as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "if (step % print_every) == 0:\n",
    "    net.eval()\n",
    "    valid_losses = []\n",
    "    for v_inputs, v_labels in valid_loader:\n",
    "        v_output, v_h = net(v_inputs)\n",
    "        v_loss = criterion(v_output, v_labels.float()) # removed v_output.squeeze()\n",
    "        valid_losses.append(v_loss.item())\n",
    "    print(\"Epoch: {}/{}\".format((epoch+1), n_epochs), \"Step: {}\".format(step),\n",
    "    \"Training Loss: {:.4f}\".format(loss.item()), \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "    net.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The working code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3 Step: 2400 Training Loss: 0.4460 Validation Loss: 0.6124\n",
      "Epoch: 2/3 Step: 4800 Training Loss: 1.5903 Validation Loss: 0.6099\n",
      "Epoch: 3/3 Step: 7200 Training Loss: 0.2195 Validation Loss: 0.6609\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "print_every = 2400\n",
    "step = 0\n",
    "n_epochs = 3\n",
    "clip = 5\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "# The main body of our training loop looks like this:\n",
    "for epoch in range(n_epochs):\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        step+=1\n",
    "        net.zero_grad()\n",
    "        output, h = net(inputs)\n",
    "        loss = criterion(output, labels.float()) # removed v_output.squeeze()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        if (step % print_every) == 0:\n",
    "            net.eval()\n",
    "            valid_losses = []\n",
    "            for v_inputs, v_labels in valid_loader:\n",
    "                v_output, v_h = net(v_inputs)\n",
    "                v_loss = criterion(v_output, v_labels.float()) # removed v_output.squeeze()\n",
    "                valid_losses.append(v_loss.item())\n",
    "            print(\"Epoch: {}/{}\".format((epoch+1), n_epochs), \"Step: {}\".format(step), \"Training Loss: {:.4f}\".format(loss.item()), \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))\n",
    "            net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that at the end of each epoch, our model calls `net.eval()` to freeze the weights of our model and performs a forward pass using our data as before. Note that dropout is also not applied when we are in evaluation mode. However, this time, instead of using the training data loader, we use the validation loader. By doing this, we can calculate the total loss of the model's current state over our validation set of data. Finally, we print our results and call `net.train()` to unfreeze our model's weights so that we can train again on the next epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save our model for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training our model for three epochs, we notice two main things. We'll start with the good news first—our model is learning something! Not only has our training loss fallen, but we can also see that our loss on the validation set has fallen after each epoch. This means that our model is better at predicting sentiment on an unseen set of data after just three epochs! The bad news, however, is that our model is massively overfitting. Our training loss is much lower than that of our validation loss, showing that while our model has learned how to predict the training set of data very well, this doesn't generalize as well to an unseen set of data. This was expected to happen as we are using a very small set of training data (just 2,400 training sentences). As we are training a whole embedding layer, it is possible that many of the words occur just once in the training set and never in the validation set and vice versa, making it practically impossible for the model to generalize all the different variety of words within our corpus. In practice, we would hope to train our model on a much larger dataset to allow our model to learn how to generalize much better. We have also trained this model over a very short time period and have not performed hyperparameter tuning to determine the best possible iteration of our model. Feel free to try changing some of the parameters within the model (such as the training time, hidden state size, embedding size, and so on) in order to improve the performance of the model.\n",
    "\n",
    "Although our model overfitted, it has still learned something. We now wish to evaluate our model on a final test set of data. We perform one final pass on the data using the test loader we defined earlier. Within this pass, we loop through all of our test data and make predictions using our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7374\n",
      "Test Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "for inputs, labels in test_loader:\n",
    "    test_output, test_h = net(inputs)\n",
    "    loss = criterion(test_output, labels.float())\n",
    "    test_losses.append(loss.item())\n",
    "\n",
    "    preds = torch.round(test_output)\n",
    "    correct_tensor = preds.eq(labels.float().view_as(preds))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test Loss: {:.4f}\".format(np.mean(test_losses)))\n",
    "print(\"Test Accuracy: {:.2f}\".format(num_correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compare our model predictions with our true labels to get `correct_tensor`, which is a vector that evaluates whether each of our model's predictions was correct. We then sum this vector and divide it by its length to get our model's total accuracy. Here, we get an accuracy of $73\\%$. While our model is certainly far from perfect, given our very small training set and limited training time, this is not bad at all! This just serves to illustrate how useful LSTMs can be when it comes to learning from NLP data. Next, we will show how we can use our model to make predictions from new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using our model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, it should be possible to repeat our preprocessing steps on a new sentence, pass this into our model, and get a prediction of it's sentiment. We first create a function to preprocess our input sentence to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    review = review.translate(str.maketrans('', '', punctuation)).lower().rstrip()\n",
    "    tokenized = word_tokenize(review)\n",
    "    if len(tokenized) >= 50:\n",
    "        review = tokenized[:50]\n",
    "    else:\n",
    "        review= ['0']*(50-len(tokenized)) + tokenized\n",
    "    final = []\n",
    "    for token in review:\n",
    "        try:\n",
    "            final.append(word_to_int_dict[token])\n",
    "        except:\n",
    "            final.append(word_to_int_dict[''])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove punctuation and trailing whitespace, convert letters into lowercase, and tokenize our input sentence as before. We pad our sentence to a sequence with a length of 50 and then convert our tokens into numeric values using our precomputed dictionary. Note that our input may contain new words that our network hasn't seen before. In this case, our function treats these as empty tokens.\n",
    "\n",
    "Next, we create our actual predict() function. We preprocess our input review, convert it into a tensor, and pass this into a data loader. We then loop through this data loader (even though it only contains one sentence) and pass our review through our network to obtain a prediction. Finally, we evaluate our prediction and print whether it is a positive or negative review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    net.eval()\n",
    "    words = np.array([preprocess_review(review)])\n",
    "    padded_words = torch.from_numpy(words)\n",
    "    pred_loader = DataLoader(padded_words, batch_size=1, shuffle=True)\n",
    "    for x in pred_loader:\n",
    "        output = net(x)[0].item()\n",
    "    \n",
    "    msg = \"This is a positive review.\" if output >= 0.5 else \"This is a negative review.\"\n",
    "    print(msg)\n",
    "    print(\"Prediction = \" + str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a positive review.\n",
      "Prediction = 0.9600074887275696\n"
     ]
    }
   ],
   "source": [
    "# Finally, we just call predict() on our review to make a prediction:\n",
    "predict(\"The film was good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a negative review.\n",
      "Prediction = 0.012057698331773281\n"
     ]
    }
   ],
   "source": [
    "# We also try using predict() on the negative value:\n",
    "predict(\"It was not good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now built an LSTM model to perform sentiment analysis from the ground up. Although our model is far from perfect, we have demonstrated how we can take some sentiment labeled reviews and train a model to be able to make predictions on new reviews. Next, we will show how we can host our model on the Heroku cloud platform so that other people can make predictions using your model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "580318c0c86e0542a7f2f9882bbbc393e6c88c07c2a75daeff3d2ea36de686a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
